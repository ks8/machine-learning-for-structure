{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import isomorphism\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import scipy.special\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from logging import Logger\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from scipy import stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataset of random, simple, complete graphs\n",
    "full_dataset_name = \"full_graph_dataset\"\n",
    "num_nodes = 10\n",
    "graphs_per_edge_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_num_low = num_nodes - 1  # Lowest number of edges (|V| - 1)\n",
    "edge_num_hi = int(scipy.special.binom(num_nodes, 2))  # Highest number of edges (complete graph)\n",
    "os.makedirs(full_dataset_name, exist_ok=True)\n",
    "counter = 0\n",
    "for i in range(edge_num_low, edge_num_hi):\n",
    "    for j in range(graphs_per_edge_number):\n",
    "        graph = nx.dense_gnm_random_graph(num_nodes, i)  # Generate a random simple graph\n",
    "        if nx.is_connected(graph):  # Record the graph if it is connected\n",
    "            for k in range(len(list(graph.degree))):  # Set node attribute to be node degree\n",
    "                graph.nodes[k]['deg'] = list(graph.degree)[k][1]\n",
    "            nx.write_gml(graph, full_dataset_name + \"/graph.\" + \"{:04d}\".format(counter))  # Write graph to file\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a training dataset of graphs with deleted edges and corresponding subisomorphism targets\n",
    "training_dataset_name = \"training_graph_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.makedirs(training_dataset_name, exist_ok=True)\n",
    "for root, subfolders, files in os.walk(full_dataset_name):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)  # File path of a graph\n",
    "        graph_number = f[-4:]\n",
    "        original_graph = nx.read_gml(path, destringizer=int)  # Read a graph from file\n",
    "        new_graph = original_graph.copy()  # Make a copy of the graph \n",
    "        d = 0.2*np.random.uniform(0, 1) + 0.7*np.random.beta(3, 3)  # Random fraction of remaining edges\n",
    "        num_deletions = int((1 - d)*(len(list(original_graph.edges))))  # Integer number of edges to delete \n",
    "        for _ in range(num_deletions):  # Delete edges from the graph\n",
    "            num_edge_to_delete = np.random.randint(0, len(list(new_graph.edges)))\n",
    "            new_graph.remove_edge(list(new_graph.edges)[num_edge_to_delete][0], list(new_graph.edges)[num_edge_to_delete][1])\n",
    "        \n",
    "        target = np.zeros([num_nodes, num_nodes])  # Target matrix showing subisomorphic edge additions as 1s\n",
    "        test_graph = new_graph.copy()  # Make a copy of the new, deleted-edges graph\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):  \n",
    "                if i < j and (i, j) not in new_graph.edges and test_graph.degree[i] < test_graph.nodes[i]['deg'] and test_graph.degree[j] < test_graph.nodes[j]['deg']:  # Check that i < j so we don't doulbe count edges, that (i, j) is not already in the graph, and that adding edge (i, j) doesn't violate any degree constraints\n",
    "                    test_graph.add_edge(i, j)  # Try adding a new edge between nodes i and j and check if it is subisomorphic\n",
    "                    if isomorphism.GraphMatcher(nx.line_graph(original_graph), nx.line_graph(test_graph)).subgraph_is_isomorphic():\n",
    "                        target[i, j] = 1.0\n",
    "                        target[j, i] = 1.0\n",
    "                    test_graph = new_graph.copy()\n",
    "        \n",
    "        nx.write_gml(new_graph, training_dataset_name + \"/partial_graph.\" + graph_number)\n",
    "        np.savetxt(training_dataset_name + \"/target.\" + graph_number, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate an evaluation dataset of graphs that have no edges and only vertices with final degree information\n",
    "evaluation_dataset_name = \"evaluation_graph_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.makedirs(evaluation_dataset_name, exist_ok = True)\n",
    "for root, subfolders, files in os.walk(full_dataset_name):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)  # File path of a graph\n",
    "        graph_number = f[-4:]\n",
    "        original_graph = nx.read_gml(path, destringizer=int)  # Read a graph from file\n",
    "        new_graph = original_graph.copy()  # Make a copy of the graph\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(num_nodes):\n",
    "                if (i, j) in new_graph.edges:\n",
    "                    new_graph.remove_edge(i, j)\n",
    "                    \n",
    "        nx.write_gml(new_graph, evaluation_dataset_name + \"/empty_graph.\" + graph_number)\n",
    "        \n",
    "        target = np.zeros([num_nodes, num_nodes])  # Empty target matrix\n",
    "        np.savetxt(evaluation_dataset_name + \"/target.\" + graph_number, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test an example\n",
    "original_graph = nx.read_gml(full_dataset_name + \"/graph.00000\", destringizer=int)\n",
    "partial_graph = nx.read_gml(training_dataset_name + \"/partial_graph.0000\", destringizer=int)\n",
    "target = np.loadtxt(training_dataset_name + \"/target.0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(original_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(partial_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[(0, 6), (1, 4), (1, 8), (2, 5), (3, 4), (7, 9)]\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "print(partial_graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph = partial_graph.copy()\n",
    "test_graph.add_edge(0, 8)\n",
    "isomorphism.GraphMatcher(nx.line_graph(original_graph), nx.line_graph(test_graph)).subgraph_is_isomorphic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'deg': 1}\n"
     ]
    }
   ],
   "source": [
    "print(partial_graph.degree[8])\n",
    "print(partial_graph.nodes[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create metadata file \n",
    "metadata_folder_name = \"metadata\"\n",
    "metadata_file_name = \"metadata.json\"\n",
    "data = []\n",
    "for root, subfolders, files in os.walk(training_dataset_name):\n",
    "    for f in files:\n",
    "        if f[:7] == \"partial\":\n",
    "            graph_path = os.path.join(root, f)\n",
    "            target_path = os.path.join(root, \"target.\"+f[-4:])\n",
    "            uid = f[f.find('.') + 1:f.find('.') + 5]\n",
    "            data.append({'graph_path': graph_path, 'target_path': target_path, 'uid': uid})\n",
    "os.makedirs(metadata_folder_name, exist_ok=True)\n",
    "json.dump(data, open(metadata_folder_name+'/'+metadata_file_name, 'w'), indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop_PyTorch \n",
    "def contains_self_loops(edge_index):\n",
    "    \"\"\"Returns a boolean for existence of self-loops in the graph\"\"\"\n",
    "    row, col = edge_index\n",
    "    mask = row == col\n",
    "    return mask.sum().item() > 0\n",
    "\n",
    "\n",
    "def remove_self_loops(edge_index, edge_attr=None):\n",
    "    \"\"\"Remove self-loops from the edge_index and edge_attr attributes\"\"\"\n",
    "    row, col = edge_index\n",
    "    mask = row != col\n",
    "    edge_attr = edge_attr if edge_attr is None else edge_attr[mask]\n",
    "    mask = mask.expand_as(edge_index)\n",
    "    edge_index = edge_index[mask].view(2, -1)\n",
    "\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# isolated_PyTorch\n",
    "def contains_isolated_nodes(edge_index, num_nodes):\n",
    "    \"\"\"Check if there are any isolated nodes\"\"\"\n",
    "    (row, _), _ = remove_self_loops(edge_index)\n",
    "    return torch.unique(row).size(0) < num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_PyTorch\n",
    "class Data(object):\n",
    "\n",
    "    def __init__(self, x=None, edge_index=None, edge_attr=None, y=None, pos=None, uid=None):\n",
    "        \"\"\"\n",
    "        Custom data class for graph objects. Note: below, 'data' refers to an example instance of Data().\n",
    "        :param x: (torch.Tensor, preferable type torch.float): node feature matrix, shape [num_nodes, num_node_features]\n",
    "        :param edge_index: (torch.Tensor of dype torch.long): graph connectivity matrix in COO format, shape [2, num_edges]\n",
    "        :param edge_attr: (torch.Tensor, preferably type torch.float): edge feature matrix,\n",
    "        shape [num_edges, num_edge_features]\n",
    "        :param y: (torch.Tensor): target data, shape arbitrary, but ideally has one dimension only\n",
    "        :param pos: (torch.Tensor of type torch.float): node position matrix, shape [num_nodes, num_dimensions]\n",
    "        :param label: str label for the data (preferably a unique identifier)\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "        self.y = y\n",
    "        self.pos = pos\n",
    "        self.uid = uid\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(dictionary):\n",
    "        \"\"\"\n",
    "        Construct a Data object with custom attributes from a dictionary of keys and items.\n",
    "        Apply as data = Data.from_dict(<some dictionary>).\n",
    "        :param dictionary: A dictionary containing custom keys and torch.Tensor items\n",
    "        :return: The Data() object\n",
    "        \"\"\"\n",
    "        data = Data()\n",
    "        for key, item in dictionary.items():\n",
    "            data[key] = item\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Access object attributes via data['key'] instead of data.key\n",
    "        :param key: Data() keys such as 'x' or 'pos'\n",
    "        :return: The corresponding attributes\n",
    "        \"\"\"\n",
    "        return getattr(self, key)\n",
    "\n",
    "    def __setitem__(self, key, item):\n",
    "        \"\"\"\n",
    "        Set object attributes via data['key']=item instead of data.key = item\n",
    "        :param key: Data() keys such as 'x' or 'pos'\n",
    "        :param item: Object attribute\n",
    "        \"\"\"\n",
    "        setattr(self, key, item)\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        \"\"\"\n",
    "        data.keys gives a list of object keys (read-only property)\n",
    "        :return: List of object keys\n",
    "        \"\"\"\n",
    "        return [key for key in self.__dict__.keys() if self[key] is not None]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        len(data) gives the number of keys in data\n",
    "        :return: Number of keys\n",
    "        \"\"\"\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        'x' in data will return True if x is in data and is not None\n",
    "        :param key: Data() key such as 'x' or 'pos'\n",
    "        :return: Boolean\n",
    "        \"\"\"\n",
    "        return key in self.keys\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Allows for iterations such as: for i in data: print(i)\n",
    "        \"\"\"\n",
    "        for key in sorted(self.keys):\n",
    "            yield key, self[key]\n",
    "\n",
    "    def __call__(self, *keys):\n",
    "        \"\"\"\n",
    "        for i in data(): print(i) will act as __iter__ above; for i in data('x', 'y'): print(i) will only\n",
    "        iterate over 'x' and 'y' keys\n",
    "        :param keys: Data() keys such as 'x' or 'pos'\n",
    "        \"\"\"\n",
    "        for key in sorted(self.keys) if not keys else keys:\n",
    "            if self[key] is not None:\n",
    "                yield key, self[key]\n",
    "\n",
    "    def cat_dim(self, key):\n",
    "        \"\"\"\n",
    "        Returns the dimension in which the attribute should be concatenated when creating batches.\n",
    "        :param key: Data() key such as 'x' or 'pos'\n",
    "        :return: Either -1 for 'edge_index' attributes or 0 otherwise\n",
    "        \"\"\"\n",
    "        return -1 if key in ['edge_index'] else 0\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self):\n",
    "        \"\"\"\n",
    "        Returns the 0th index of data.x or data.pos for the number of nodes in the system. data.x and data.pos should\n",
    "        have the same 0th index.\n",
    "        :return: Number of nodes\n",
    "        \"\"\"\n",
    "        for key, item in self('x', 'pos'):\n",
    "            return item.size(0)\n",
    "        return None\n",
    "\n",
    "    @property \n",
    "    def num_edges(self):\n",
    "        \"\"\"\n",
    "        Returns the 1th index for data.edge_index and the 0th index for data.edge_attr, corresponding to the number\n",
    "        of edges in the graph\n",
    "        :return: Number of edges\n",
    "        \"\"\"\n",
    "        for key, item in self('edge_index', 'edge_attr'):\n",
    "            if key == 'edge_index':\n",
    "                return item.size(1)\n",
    "            else:\n",
    "                return item.size(0)\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def num_features(self):\n",
    "        \"\"\"\n",
    "        Number of features, encoded in data.x\n",
    "        :return: Number of features\n",
    "        \"\"\"\n",
    "        return 1 if self.x.dim() == 1 else self.x.size(1)\n",
    "\n",
    "    def contains_isolated_nodes(self):\n",
    "        \"\"\"\n",
    "        Whether or not the graph contains isolated nodes\n",
    "        :return: Boolean\n",
    "        \"\"\"\n",
    "        return contains_isolated_nodes(self.edge_index, self.num_nodes)\n",
    "\n",
    "    def contains_self_loops(self):\n",
    "        \"\"\"\n",
    "        Whether or not the graph contains self-loops\n",
    "        :return: Boolean\n",
    "        \"\"\"\n",
    "        return contains_self_loops(self.edge_index)\n",
    "\n",
    "    def apply(self, func, *keys):\n",
    "        \"\"\"\n",
    "        Apply a function to every key (if *keys is blank) or to a specific set of keys\n",
    "        :param func: Some function that will act on every element of a data attribute\n",
    "        :param keys: Data() keys such as 'x' or 'pos'\n",
    "        :return: The modified Data() object\n",
    "        \"\"\"\n",
    "        for key, item in self(*keys):\n",
    "            self[key] = func(item)\n",
    "        return self\n",
    "\n",
    "    def contiguous(self, *keys):\n",
    "        \"\"\"\n",
    "        Apply PyTorch contiguity to every key (if *keys is blank) or to a specific set of keys\n",
    "        :param keys: Data() keys such as 'x' or 'pos'\n",
    "        :return: The modified Data() object\n",
    "        \"\"\"\n",
    "        return self.apply(lambda x: x.contiguous(), *keys)\n",
    "\n",
    "    def to(self, device, *keys):\n",
    "        \"\"\"\n",
    "        Move data attributes to device. data.to(device) moves all attributes to device, while\n",
    "        data.to(device, 'x', 'pos') moves only data.x and data.pos to device\n",
    "        :param device:\n",
    "        :param keys:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.apply(lambda x: x.to(device), *keys)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        :return: Representation of class in interpreter\n",
    "        \"\"\"\n",
    "        info = ['{}={}'.format(key, list(item.size())) for key, item in self]\n",
    "        return '{}({})'.format(self.__class__.__name__, ', '.join(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class GraphDataset(Dataset):\n",
    "\n",
    "    def __init__(self, metadata, transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for random graphs\n",
    "        :param metadata: Metadata contents\n",
    "        :param transform: Transform to apply to the data (can be a Compose() object)\n",
    "        \"\"\"\n",
    "        super(Dataset, self).__init__()\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Output a data object with node features, edge connectivity, and target vector\"\"\"       \n",
    "        data = Data()  # Create data object\n",
    "        \n",
    "        # Read in data\n",
    "        graph = nx.read_gml(self.metadata[idx]['graph_path'], destringizer=int)  # Read in the partial graph\n",
    "        target = np.loadtxt(self.metadata[idx]['target_path'])  # Read in the target matrix of allowed edges\n",
    "        num_nodes = len(list(graph.nodes))  # Compute the number of nodes in the graph \n",
    "        \n",
    "        # Compute node features\n",
    "        one_hot_features = np.zeros((num_nodes, num_nodes))  # Create a one-hot mapping for remaining node degree\n",
    "        np.fill_diagonal(one_hot_features, 1.)\n",
    "        raw_features = np.array([[graph.nodes[i]['deg'], graph.degree[i], graph.nodes[i]['deg'] - graph.degree[i]] for i in range(num_nodes)])  # Compute the original node degree, current node degree, and remaining node degree\n",
    "        one_hot_features = np.array([one_hot_features[graph.nodes[i]['deg'] - graph.degree[i]] for i in range(num_nodes)])  # Compute one-hot encoding for remaining node degree\n",
    "        data.x = torch.tensor(np.concatenate((raw_features, one_hot_features), axis=1), dtype=torch.float)  # Node features: concatenate the raw features and one-hot encoded features \n",
    "        \n",
    "        # Compute targets\n",
    "        data.y = torch.tensor(target[np.triu_indices(num_nodes, k=1)], dtype=torch.float)  # Target: 1-d tensor derived from upper triangle (not including main diagonal) of the target matrix\n",
    "        \n",
    "        # Compute graph id\n",
    "        data.uid = torch.tensor([int(self.metadata[idx]['uid'])])  # Unique id\n",
    "        \n",
    "        # Compute edge connectivity in COO format corresponding to a complete graph on num_nodes\n",
    "        complete_graph = np.ones([num_nodes, num_nodes])  # Create an auxiliary complete graph\n",
    "        complete_graph = np.triu(complete_graph, k=1)  # Compute an upper triangular matrix of the complete graph, with zeros on main diagonal\n",
    "        complete_graph = scipy.sparse.csc_matrix(complete_graph)  # Compute a csc style sparse matrix from this graph\n",
    "        row, col = complete_graph.nonzero()  # Extract the row and column indices corresponding to non-zero entries\n",
    "        row = torch.tensor(row, dtype=torch.long)\n",
    "        col = torch.tensor(col, dtype=torch.long)\n",
    "        data.edge_index = torch.stack([row, col], dim=0)  # Edge connectivity in COO format (includes *all* possible edges in graphs with a given num_nodes)\n",
    "        \n",
    "        # Compute edge attributes, i.e., 1 if the edge is actually present in the graph, 0 otherwise\n",
    "        data.edge_attr = torch.tensor([[i] for i in np.array(nx.to_numpy_matrix(graph))[np.triu_indices(num_nodes, k=1)]], dtype=torch.float)  # Attributes: 1-d tensor derived from upper triangle (not including main diagonal) of actual edges that are present in the graph   \n",
    "    \n",
    "    \n",
    "        # Transform \n",
    "        data = data if self.transform is None else self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.__class__.__name__, len(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batch(Data):\n",
    "    \"\"\"\n",
    "    Batch class for mini-batch parallelization. All of the methods of class Data can be used.\n",
    "    In addition, single graphs can be reconstructed via the assignment vector, batch, which\n",
    "    maps each node to its respective graph identifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch=None, **kwargs):\n",
    "        super(Batch, self).__init__(**kwargs)\n",
    "        self.batch = batch\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data_list(data_list):\n",
    "        \"\"\"Constructs an object of class Batch from a list of graphs generated by a DataLoader\"\"\"\n",
    "\n",
    "        keys = data_list[0].keys\n",
    "        assert 'batch' not in keys\n",
    "\n",
    "        batch = Batch()\n",
    "\n",
    "        for key in keys:\n",
    "            batch[key] = []\n",
    "        batch.batch = []\n",
    "\n",
    "        cumsum = 0\n",
    "        for i, data in enumerate(data_list):\n",
    "            num_nodes = data.num_nodes\n",
    "            batch.batch.append(torch.full((num_nodes, ), i, dtype=torch.long))\n",
    "            for key in keys:\n",
    "                item = data[key]\n",
    "                # Ensures that the cumulative edge_index matrix of the batch will\n",
    "                # have different sets of indices for each subgraph of the batch\n",
    "                item = item + cumsum if batch.cumsum(key) else item\n",
    "                batch[key].append(item)\n",
    "            cumsum += num_nodes\n",
    "\n",
    "        for key in keys:\n",
    "            # Concatenates batch['edge_index'] differently than the others (and also possibly batch['y'])\n",
    "            batch[key] = torch.cat(batch[key], dim=data_list[0].cat_dim(key))\n",
    "        batch.batch = torch.cat(batch.batch, dim=-1)\n",
    "        return batch.contiguous()\n",
    "\n",
    "    def cumsum(self, key):\n",
    "        \"\"\"\n",
    "        Checks for the presence of 'edge_index' attribute for determining how to index values\n",
    "        :param key: Data() attributes such as 'x' or 'pos'\n",
    "        :return: Boolean\n",
    "        \"\"\"\n",
    "        return key in ['edge_index']\n",
    "\n",
    "    @property\n",
    "    def num_graphs(self):\n",
    "        \"\"\"Compute the number of graphs in the batch\"\"\"\n",
    "        return self.batch[-1].item() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(torch.utils.data.DataLoader):\n",
    "\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a Dataloader object using the custom collate_fn from Batch class\n",
    "        :param dataset: Dataset to be used\n",
    "        :param batch_size: Batch size\n",
    "        :param shuffle: Whether or not to shuffle data\n",
    "        :param kwargs: Other arguments\n",
    "        \"\"\"\n",
    "        super(DataLoader, self).__init__(\n",
    "            dataset,\n",
    "            batch_size,\n",
    "            shuffle,\n",
    "            collate_fn=lambda batch: Batch.from_data_list(batch),\n",
    "            **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_undirected(edge_index, num_nodes):\n",
    "    \"\"\"Returns an undirected (bidirectional) COO format connectivity matrix from an original matrix given by edge_index\"\"\"\n",
    "\n",
    "    row, col = edge_index\n",
    "    row, col = torch.cat([row, col], dim=0), torch.cat([col, row], dim=0)\n",
    "    unique, inv = torch.unique(row*num_nodes + col, sorted=True, return_inverse=True)\n",
    "    perm = torch.arange(inv.size(0), dtype=inv.dtype, device=inv.device)\n",
    "    perm = inv.new_empty(unique.size(0)).scatter_(0, inv, perm)\n",
    "    index = torch.stack([row[perm], col[perm]], dim=0)\n",
    "\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "train size = 828 | val size = 103 | test size = 104\n"
     ]
    }
   ],
   "source": [
    "metadata = json.load(open(metadata_folder_name+'/'+metadata_file_name, 'r'))\n",
    "val_test_size = 0.2\n",
    "seed = 0\n",
    "batch_size = 5\n",
    "\n",
    "train_metadata, remaining_metadata = train_test_split(metadata, test_size=val_test_size, random_state=seed)\n",
    "validation_metadata, test_metadata = train_test_split(remaining_metadata, test_size=0.5, random_state=seed)\n",
    "\n",
    "print(\"loading data\")\n",
    "train_data = GraphDataset(train_metadata)\n",
    "val_data = GraphDataset(validation_metadata)\n",
    "test_data = GraphDataset(test_metadata)\n",
    "\n",
    "train_data_length, val_data_length, test_data_length = len(train_data), len(val_data), len(test_data)\n",
    "print('train size = {:,} | val size = {:,} | test size = {:,}'.format(\n",
    "    train_data_length,\n",
    "    val_data_length,\n",
    "    test_data_length)\n",
    ")\n",
    "\n",
    "# Convert to iterators\n",
    "train_data = DataLoader(train_data, batch_size)\n",
    "val_data = DataLoader(val_data, batch_size)\n",
    "test_data = DataLoader(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset_iter = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch = dataset_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCELoss(reduction='none')\n",
    "metric_func = roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RelationalNetwork(torch.nn.Module):\n",
    "    \"\"\" Relational network definition \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size = 256, num_layers = 32, num_edge_features = None, num_vertex_features = None, final_linear_size = 1024):\n",
    "        \n",
    "        super(RelationalNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size  # Internal feature size\n",
    "        self.num_layers = num_layers  # Number of relational layers\n",
    "        self.num_edge_features = num_edge_features  # Number of input edge features\n",
    "        self.num_vertex_features = num_vertex_features  # Number of input vertex features\n",
    "        self.final_linear_size = final_linear_size  # Number of nodes in final linear layer\n",
    "        self.edge_featurize = torch.nn.Linear(self.num_edge_features, self.hidden_size)  # Initial linear layer for featurization of edge features\n",
    "        self.vertex_featurize = torch.nn.Linear(self.num_vertex_features, self.hidden_size)  # Initial linear layer for featurization of vertex features\n",
    "        self.L_e = torch.nn.ModuleList([torch.nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.num_layers)])  # Linear layers for edges\n",
    "        self.L_v = torch.nn.ModuleList([torch.nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.num_layers)])  # Linear layers for vertices\n",
    "        self.edge_batch_norm = torch.nn.ModuleList([torch.nn.BatchNorm1d(self.hidden_size) for _ in range(self.num_layers)])  # Batch norms for edges (\\phi_e)\n",
    "        self.vertex_batch_norm = torch.nn.ModuleList([torch.nn.BatchNorm1d(self.hidden_size) for _ in range(self.num_layers)])  # Batch norms for vertices (\\phi_v)\n",
    "        self.gru = torch.nn.ModuleList([torch.nn.GRU(self.hidden_size, self.hidden_size) for _ in range(self.num_layers)])  # GRU cells\n",
    "        self.final_linear_layer = torch.nn.Linear(self.hidden_size, self.final_linear_size)  # Final linear layer\n",
    "        self.output_layer = torch.nn.Linear(self.final_linear_size, 1)  # Output layer\n",
    "        self.sigmoid = torch.nn.Sigmoid()  # Sigmoid for 0/1 predictions\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        e_ij_in = self.edge_featurize(batch.edge_attr)  # Featurization \n",
    "        v_i_in = self.vertex_featurize(batch.x)\n",
    "        \n",
    "        for k in range(self.num_layers):\n",
    "            e_ij = self.L_e[k](e_ij_in)  # Linear layer for edges\n",
    "            v_i_prime = self.L_v[k](v_i_in)  # Linear layer for vertices\n",
    "            e_ij_prime = F.relu(self.edge_batch_norm[k](torch.stack([e_ij[edge_num] + v_i_prime[batch.edge_index[0][edge_num]] + v_i_prime[batch.edge_index[1][edge_num]] for edge_num in range(e_ij.size(0))])))  # Add pairwise vertex features to edge features followed by batch norm and ReLU \n",
    "            undirected_edge_index = to_undirected(batch.edge_index, batch.num_nodes)  # Full set of undirected edges for bookkeeping\n",
    "            v_i_e = torch.stack([torch.max(e_ij_prime[np.array([np.intersect1d(np.where(batch.edge_index[0] == min(vertex_num, i)), np.where(batch.edge_index[1] == max(vertex_num, i))) for i in np.array(undirected_edge_index[1][np.where(undirected_edge_index[0] == vertex_num)])]).flatten()], 0)[0] for vertex_num in range(batch.num_nodes)])  # Aggregate edge features                             \n",
    "            gru_input = v_i_e.view(1, batch.num_nodes, self.hidden_size)  # Resize GRU input\n",
    "            gru_hidden = v_i_in.view(1, batch.num_nodes, self.hidden_size)  # Resize GRU hidden\n",
    "            gru_output, _ = self.gru[k](gru_input, gru_hidden)  # Compute GRU output\n",
    "            v_i_c = F.relu(self.vertex_batch_norm[k](gru_output.view(batch.num_nodes, self.hidden_size)))  # Apply batch norm and ReLU to GRU output\n",
    "            v_i_in = v_i_c + v_i_in  # Add residual connection to vertex input \n",
    "            e_ij_in = e_ij_prime + e_ij_in  # Add residual connection to edge input\n",
    "            \n",
    "        e_ij_final = self.final_linear_layer(e_ij_in)  # Compute final linear layer\n",
    "        out = self.output_layer(e_ij_final)  # Output layer\n",
    "        preds = self.sigmoid(out)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RelationalNetwork(hidden_size=256, num_layers = 3, num_edge_features = 1, num_vertex_features = 13, final_linear_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, data, loss_func, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for batch in tqdm(data, total=len(data)):\n",
    "        model.zero_grad()\n",
    "        targets = batch.y.unsqueeze(1)\n",
    "        preds = model(batch)\n",
    "        loss = loss_func(preds, batch.y.unsqueeze(1))\n",
    "        loss = loss.sum() / batch.num_graphs\n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    loss_avg = loss_sum / len(data)\n",
    "    print('train loss: ', loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data, metric_func):\n",
    "    \n",
    "    targets = []\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for batch in tqdm(data, total=len(data)):\n",
    "            targets.extend(batch.y.numpy())\n",
    "            batch_preds = model(batch)\n",
    "            preds.extend(batch_preds.numpy())\n",
    "    \n",
    "    return metric_func(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, path):\n",
    "    \"\"\"\n",
    "    Saves a model checkpoint.\n",
    "    :param model: A PyTorch model.\n",
    "    :param path: Path where checkpoint will be saved.\n",
    "    \"\"\"\n",
    "    state = {\n",
    "        'state_dict': model.state_dict()\n",
    "    }\n",
    "    torch.save(state, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/166 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/166 [00:00<01:55,  1.43it/s]\u001b[A\n",
      "  1%|          | 2/166 [00:01<01:48,  1.52it/s]\u001b[A\n",
      "  2%|         | 3/166 [00:01<01:43,  1.58it/s]\u001b[A\n",
      "  2%|         | 4/166 [00:02<01:38,  1.64it/s]\u001b[A\n",
      "  3%|         | 5/166 [00:02<01:36,  1.66it/s]\u001b[A\n",
      "  4%|         | 6/166 [00:03<01:37,  1.63it/s]\u001b[A\n",
      "  4%|         | 7/166 [00:04<01:34,  1.67it/s]\u001b[A\n",
      "  5%|         | 8/166 [00:04<01:32,  1.70it/s]\u001b[A\n",
      "  5%|         | 9/166 [00:05<01:31,  1.72it/s]\u001b[A\n",
      "  6%|         | 10/166 [00:05<01:31,  1.70it/s]\u001b[A\n",
      "  7%|         | 11/166 [00:06<01:30,  1.71it/s]\u001b[A\n",
      "  7%|         | 12/166 [00:07<01:29,  1.72it/s]\u001b[A\n",
      "  8%|         | 13/166 [00:07<01:28,  1.72it/s]\u001b[A\n",
      "  8%|         | 14/166 [00:08<01:28,  1.73it/s]\u001b[A\n",
      "  9%|         | 15/166 [00:08<01:28,  1.71it/s]\u001b[A\n",
      " 10%|         | 16/166 [00:09<01:27,  1.72it/s]\u001b[A\n",
      " 10%|         | 17/166 [00:09<01:25,  1.74it/s]\u001b[A\n",
      " 11%|         | 18/166 [00:10<01:26,  1.72it/s]\u001b[A\n",
      " 11%|        | 19/166 [00:11<01:26,  1.70it/s]\u001b[A\n",
      " 12%|        | 20/166 [00:11<01:25,  1.70it/s]\u001b[A\n",
      " 13%|        | 21/166 [00:12<01:25,  1.70it/s]\u001b[A\n",
      " 13%|        | 22/166 [00:12<01:24,  1.70it/s]\u001b[A\n",
      " 14%|        | 23/166 [00:13<01:23,  1.71it/s]\u001b[A\n",
      " 14%|        | 24/166 [00:14<01:24,  1.69it/s]\u001b[A\n",
      " 15%|        | 25/166 [00:14<01:23,  1.68it/s]\u001b[A\n",
      " 16%|        | 26/166 [00:15<01:22,  1.69it/s]\u001b[A\n",
      " 16%|        | 27/166 [00:15<01:23,  1.66it/s]\u001b[A\n",
      " 17%|        | 28/166 [00:16<01:22,  1.67it/s]\u001b[A\n",
      " 17%|        | 29/166 [00:17<01:20,  1.69it/s]\u001b[A\n",
      " 18%|        | 30/166 [00:17<01:20,  1.68it/s]\u001b[A\n",
      " 19%|        | 31/166 [00:18<01:19,  1.69it/s]\u001b[A\n",
      " 19%|        | 32/166 [00:18<01:19,  1.69it/s]\u001b[A\n",
      " 20%|        | 33/166 [00:19<01:19,  1.67it/s]\u001b[A\n",
      " 20%|        | 34/166 [00:20<01:18,  1.68it/s]\u001b[A\n",
      " 21%|        | 35/166 [00:20<01:17,  1.68it/s]\u001b[A\n",
      " 22%|       | 36/166 [00:21<01:18,  1.65it/s]\u001b[A\n",
      " 22%|       | 37/166 [00:21<01:16,  1.68it/s]\u001b[A\n",
      " 23%|       | 38/166 [00:22<01:16,  1.68it/s]\u001b[A\n",
      " 23%|       | 39/166 [00:23<01:17,  1.64it/s]\u001b[A\n",
      " 24%|       | 40/166 [00:23<01:16,  1.65it/s]\u001b[A\n",
      " 25%|       | 41/166 [00:24<01:14,  1.67it/s]\u001b[A\n",
      " 25%|       | 42/166 [00:24<01:14,  1.66it/s]\u001b[A\n",
      " 26%|       | 43/166 [00:25<01:13,  1.68it/s]\u001b[A\n",
      " 27%|       | 44/166 [00:26<01:12,  1.67it/s]\u001b[A\n",
      " 27%|       | 45/166 [00:26<01:12,  1.66it/s]\u001b[A\n",
      " 28%|       | 46/166 [00:27<01:11,  1.68it/s]\u001b[A\n",
      " 28%|       | 47/166 [00:27<01:10,  1.69it/s]\u001b[A\n",
      " 29%|       | 48/166 [00:28<01:10,  1.68it/s]\u001b[A\n",
      " 30%|       | 49/166 [00:29<01:08,  1.70it/s]\u001b[A\n",
      " 30%|       | 50/166 [00:29<01:08,  1.71it/s]\u001b[A\n",
      " 31%|       | 51/166 [00:30<01:08,  1.68it/s]\u001b[A\n",
      " 31%|      | 52/166 [00:30<01:07,  1.70it/s]\u001b[A\n",
      " 32%|      | 53/166 [00:31<01:06,  1.70it/s]\u001b[A\n",
      " 33%|      | 54/166 [00:31<01:06,  1.68it/s]\u001b[A\n",
      " 33%|      | 55/166 [00:32<01:05,  1.70it/s]\u001b[A\n",
      " 34%|      | 56/166 [00:33<01:04,  1.71it/s]\u001b[A\n",
      " 34%|      | 57/166 [00:33<01:04,  1.70it/s]\u001b[A\n",
      " 35%|      | 58/166 [00:34<01:03,  1.71it/s]\u001b[A\n",
      " 36%|      | 59/166 [00:34<01:02,  1.71it/s]\u001b[A\n",
      " 36%|      | 60/166 [00:35<01:02,  1.70it/s]\u001b[A\n",
      " 37%|      | 61/166 [00:36<01:00,  1.72it/s]\u001b[A\n",
      " 37%|      | 62/166 [00:36<01:00,  1.72it/s]\u001b[A\n",
      " 38%|      | 63/166 [00:37<01:00,  1.71it/s]\u001b[A\n",
      " 39%|      | 64/166 [00:37<01:00,  1.69it/s]\u001b[A\n",
      " 39%|      | 65/166 [00:38<00:59,  1.71it/s]\u001b[A\n",
      " 40%|      | 66/166 [00:39<00:59,  1.69it/s]\u001b[A\n",
      " 40%|      | 67/166 [00:39<00:58,  1.69it/s]\u001b[A\n",
      " 41%|      | 68/166 [00:40<00:57,  1.71it/s]\u001b[A\n",
      " 42%|     | 69/166 [00:40<00:57,  1.67it/s]\u001b[A\n",
      " 42%|     | 70/166 [00:41<00:56,  1.69it/s]\u001b[A\n",
      " 43%|     | 71/166 [00:41<00:55,  1.70it/s]\u001b[A\n",
      " 43%|     | 72/166 [00:42<00:55,  1.69it/s]\u001b[A\n",
      " 44%|     | 73/166 [00:43<00:54,  1.69it/s]\u001b[A\n",
      " 45%|     | 74/166 [00:43<00:53,  1.71it/s]\u001b[A\n",
      " 45%|     | 75/166 [00:44<00:53,  1.70it/s]\u001b[A\n",
      " 46%|     | 76/166 [00:44<00:53,  1.70it/s]\u001b[A\n",
      " 46%|     | 77/166 [00:45<00:52,  1.69it/s]\u001b[A\n",
      " 47%|     | 78/166 [00:46<00:52,  1.67it/s]\u001b[A\n",
      " 48%|     | 79/166 [00:46<00:51,  1.68it/s]\u001b[A\n",
      " 48%|     | 80/166 [00:47<00:50,  1.70it/s]\u001b[A\n",
      " 49%|     | 81/166 [00:47<00:50,  1.68it/s]\u001b[A\n",
      " 49%|     | 82/166 [00:48<00:49,  1.69it/s]\u001b[A\n",
      " 50%|     | 83/166 [00:49<00:53,  1.55it/s]\u001b[A\n",
      " 51%|     | 84/166 [00:50<00:57,  1.42it/s]\u001b[A\n",
      " 51%|     | 85/166 [00:50<00:53,  1.50it/s]\u001b[A\n",
      " 52%|    | 86/166 [00:51<00:51,  1.56it/s]\u001b[A\n",
      " 52%|    | 87/166 [00:51<00:49,  1.59it/s]\u001b[A\n",
      " 53%|    | 88/166 [00:52<00:48,  1.62it/s]\u001b[A\n",
      " 54%|    | 89/166 [00:53<00:48,  1.59it/s]\u001b[A\n",
      " 54%|    | 90/166 [00:53<00:47,  1.61it/s]\u001b[A\n",
      " 55%|    | 91/166 [00:54<00:45,  1.64it/s]\u001b[A\n",
      " 55%|    | 92/166 [00:54<00:47,  1.57it/s]\u001b[A\n",
      " 56%|    | 93/166 [00:55<00:46,  1.58it/s]\u001b[A\n",
      " 57%|    | 94/166 [00:56<00:44,  1.62it/s]\u001b[A\n",
      " 57%|    | 95/166 [00:56<00:43,  1.63it/s]\u001b[A\n",
      " 58%|    | 96/166 [00:57<00:43,  1.61it/s]\u001b[A\n",
      " 58%|    | 97/166 [00:58<00:41,  1.64it/s]\u001b[A\n",
      " 59%|    | 98/166 [00:58<00:40,  1.68it/s]\u001b[A\n",
      " 60%|    | 99/166 [00:59<00:40,  1.66it/s]\u001b[A\n",
      " 60%|    | 100/166 [00:59<00:39,  1.68it/s]\u001b[A\n",
      " 61%|    | 101/166 [01:00<00:38,  1.69it/s]\u001b[A\n",
      " 61%|   | 102/166 [01:00<00:38,  1.68it/s]\u001b[A\n",
      " 62%|   | 103/166 [01:01<00:37,  1.70it/s]\u001b[A\n",
      " 63%|   | 104/166 [01:02<00:37,  1.66it/s]\u001b[A\n",
      " 63%|   | 105/166 [01:02<00:37,  1.62it/s]\u001b[A\n",
      " 64%|   | 106/166 [01:03<00:36,  1.65it/s]\u001b[A\n",
      " 64%|   | 107/166 [01:03<00:35,  1.68it/s]\u001b[A\n",
      " 65%|   | 108/166 [01:04<00:34,  1.66it/s]\u001b[A\n",
      " 66%|   | 109/166 [01:05<00:33,  1.70it/s]\u001b[A\n",
      " 66%|   | 110/166 [01:05<00:32,  1.73it/s]\u001b[A\n",
      " 67%|   | 111/166 [01:06<00:32,  1.71it/s]\u001b[A\n",
      " 67%|   | 112/166 [01:06<00:31,  1.73it/s]\u001b[A\n",
      " 68%|   | 113/166 [01:07<00:30,  1.75it/s]\u001b[A\n",
      " 69%|   | 114/166 [01:08<00:30,  1.72it/s]\u001b[A\n",
      " 69%|   | 115/166 [01:08<00:29,  1.73it/s]\u001b[A\n",
      " 70%|   | 116/166 [01:09<00:28,  1.76it/s]\u001b[A\n",
      " 70%|   | 117/166 [01:09<00:28,  1.74it/s]\u001b[A\n",
      " 71%|   | 118/166 [01:10<00:27,  1.75it/s]\u001b[A\n",
      " 72%|  | 119/166 [01:10<00:26,  1.75it/s]\u001b[A\n",
      " 72%|  | 120/166 [01:11<00:26,  1.72it/s]\u001b[A\n",
      " 73%|  | 121/166 [01:12<00:26,  1.73it/s]\u001b[A\n",
      " 73%|  | 122/166 [01:12<00:25,  1.73it/s]\u001b[A\n",
      " 74%|  | 123/166 [01:13<00:24,  1.72it/s]\u001b[A\n",
      " 75%|  | 124/166 [01:13<00:26,  1.60it/s]\u001b[A\n",
      " 75%|  | 125/166 [01:15<00:35,  1.15it/s]\u001b[A\n",
      " 76%|  | 126/166 [01:16<00:34,  1.15it/s]\u001b[A\n",
      " 77%|  | 127/166 [01:17<00:43,  1.10s/it]\u001b[A\n",
      " 77%|  | 128/166 [01:18<00:36,  1.05it/s]\u001b[A\n",
      " 78%|  | 129/166 [01:19<00:34,  1.06it/s]\u001b[A\n",
      " 78%|  | 130/166 [01:20<00:30,  1.19it/s]\u001b[A\n",
      " 79%|  | 131/166 [01:20<00:26,  1.31it/s]\u001b[A\n",
      " 80%|  | 132/166 [01:21<00:24,  1.39it/s]\u001b[A\n",
      " 80%|  | 133/166 [01:21<00:22,  1.47it/s]\u001b[A\n",
      " 81%|  | 134/166 [01:22<00:20,  1.55it/s]\u001b[A\n",
      " 81%| | 135/166 [01:23<00:20,  1.53it/s]\u001b[A\n",
      " 82%| | 136/166 [01:23<00:18,  1.59it/s]\u001b[A\n",
      " 83%| | 137/166 [01:24<00:17,  1.62it/s]\u001b[A\n",
      " 83%| | 138/166 [01:24<00:17,  1.62it/s]\u001b[A\n",
      " 84%| | 139/166 [01:25<00:16,  1.65it/s]\u001b[A\n",
      " 84%| | 140/166 [01:25<00:15,  1.66it/s]\u001b[A\n",
      " 85%| | 141/166 [01:26<00:15,  1.65it/s]\u001b[A\n",
      " 86%| | 142/166 [01:27<00:14,  1.68it/s]\u001b[A\n",
      " 86%| | 143/166 [01:27<00:13,  1.69it/s]\u001b[A\n",
      " 87%| | 144/166 [01:28<00:12,  1.69it/s]\u001b[A\n",
      " 87%| | 145/166 [01:28<00:12,  1.71it/s]\u001b[A\n",
      " 88%| | 146/166 [01:29<00:11,  1.72it/s]\u001b[A\n",
      " 89%| | 147/166 [01:30<00:11,  1.69it/s]\u001b[A\n",
      " 89%| | 148/166 [01:30<00:10,  1.71it/s]\u001b[A\n",
      " 90%| | 149/166 [01:31<00:11,  1.51it/s]\u001b[A\n",
      " 90%| | 150/166 [01:32<00:12,  1.30it/s]\u001b[A\n",
      " 91%| | 151/166 [01:33<00:13,  1.10it/s]\u001b[A\n",
      " 92%|| 152/166 [01:34<00:11,  1.24it/s]\u001b[A\n",
      " 92%|| 153/166 [01:35<00:10,  1.20it/s]\u001b[A\n",
      " 93%|| 154/166 [01:35<00:09,  1.31it/s]\u001b[A\n",
      " 93%|| 155/166 [01:36<00:07,  1.40it/s]\u001b[A\n",
      " 94%|| 156/166 [01:37<00:06,  1.46it/s]\u001b[A\n",
      " 95%|| 157/166 [01:37<00:05,  1.52it/s]\u001b[A\n",
      " 95%|| 158/166 [01:38<00:05,  1.59it/s]\u001b[A\n",
      " 96%|| 159/166 [01:38<00:04,  1.60it/s]\u001b[A\n",
      " 96%|| 160/166 [01:39<00:03,  1.64it/s]\u001b[A\n",
      " 97%|| 161/166 [01:39<00:02,  1.68it/s]\u001b[A\n",
      " 98%|| 162/166 [01:40<00:02,  1.68it/s]\u001b[A\n",
      " 98%|| 163/166 [01:41<00:01,  1.67it/s]\u001b[A\n",
      " 99%|| 164/166 [01:41<00:01,  1.68it/s]\u001b[A\n",
      " 99%|| 165/166 [01:42<00:00,  1.68it/s]\u001b[A\n",
      "100%|| 166/166 [01:42<00:00,  1.62it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  7.15328634503376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|         | 1/21 [00:00<00:06,  3.29it/s]\u001b[A\n",
      " 10%|         | 2/21 [00:00<00:05,  3.34it/s]\u001b[A\n",
      " 14%|        | 3/21 [00:00<00:05,  3.39it/s]\u001b[A\n",
      " 19%|        | 4/21 [00:01<00:05,  3.37it/s]\u001b[A\n",
      " 24%|       | 5/21 [00:01<00:04,  3.42it/s]\u001b[A\n",
      " 29%|       | 6/21 [00:01<00:04,  3.46it/s]\u001b[A\n",
      " 33%|      | 7/21 [00:02<00:04,  3.32it/s]\u001b[A\n",
      " 38%|      | 8/21 [00:02<00:03,  3.32it/s]\u001b[A\n",
      " 43%|     | 9/21 [00:02<00:03,  3.35it/s]\u001b[A\n",
      " 48%|     | 10/21 [00:02<00:03,  3.39it/s]\u001b[A\n",
      " 52%|    | 11/21 [00:03<00:02,  3.39it/s]\u001b[A\n",
      " 57%|    | 12/21 [00:03<00:02,  3.45it/s]\u001b[A\n",
      " 62%|   | 13/21 [00:03<00:02,  3.45it/s]\u001b[A\n",
      " 67%|   | 14/21 [00:04<00:02,  3.40it/s]\u001b[A\n",
      " 71%|  | 15/21 [00:04<00:01,  3.43it/s]\u001b[A\n",
      " 76%|  | 16/21 [00:04<00:01,  3.40it/s]\u001b[A\n",
      " 81%|  | 17/21 [00:04<00:01,  3.45it/s]\u001b[A\n",
      " 86%| | 18/21 [00:05<00:00,  3.45it/s]\u001b[A\n",
      " 90%| | 19/21 [00:05<00:00,  3.49it/s]\u001b[A\n",
      " 95%|| 20/21 [00:05<00:00,  3.47it/s]\u001b[A\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\u001b[A\n",
      " 50%|     | 1/2 [01:48<01:48, 108.72s/it]\n",
      "  0%|          | 0/166 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/166 [00:00<01:26,  1.91it/s]\u001b[A\n",
      "  1%|          | 2/166 [00:01<01:25,  1.91it/s]\u001b[A\n",
      "  2%|         | 3/166 [00:01<01:24,  1.94it/s]\u001b[A\n",
      "  2%|         | 4/166 [00:02<01:23,  1.94it/s]\u001b[A\n",
      "  3%|         | 5/166 [00:02<01:23,  1.93it/s]\u001b[A\n",
      "  4%|         | 6/166 [00:03<01:23,  1.93it/s]\u001b[A\n",
      "  4%|         | 7/166 [00:03<01:23,  1.90it/s]\u001b[A\n",
      "  5%|         | 8/166 [00:04<01:23,  1.90it/s]\u001b[A\n",
      "  5%|         | 9/166 [00:04<01:22,  1.91it/s]\u001b[A\n",
      "  6%|         | 10/166 [00:05<01:21,  1.93it/s]\u001b[A\n",
      "  7%|         | 11/166 [00:05<01:19,  1.94it/s]\u001b[A\n",
      "  7%|         | 12/166 [00:06<01:21,  1.89it/s]\u001b[A\n",
      "  8%|         | 13/166 [00:06<01:20,  1.89it/s]\u001b[A\n",
      "  8%|         | 14/166 [00:07<01:19,  1.90it/s]\u001b[A\n",
      "  9%|         | 15/166 [00:07<01:19,  1.90it/s]\u001b[A\n",
      " 10%|         | 16/166 [00:08<01:18,  1.92it/s]\u001b[A\n",
      " 10%|         | 17/166 [00:08<01:16,  1.94it/s]\u001b[A\n",
      " 11%|         | 18/166 [00:09<01:17,  1.91it/s]\u001b[A\n",
      " 11%|        | 19/166 [00:09<01:16,  1.92it/s]\u001b[A\n",
      " 12%|        | 20/166 [00:10<01:16,  1.90it/s]\u001b[A\n",
      " 13%|        | 21/166 [00:10<01:16,  1.88it/s]\u001b[A\n",
      " 13%|        | 22/166 [00:11<01:16,  1.88it/s]\u001b[A\n",
      " 14%|        | 23/166 [00:12<01:15,  1.90it/s]\u001b[A\n",
      " 14%|        | 24/166 [00:12<01:15,  1.87it/s]\u001b[A\n",
      " 15%|        | 25/166 [00:13<01:14,  1.89it/s]\u001b[A\n",
      " 16%|        | 26/166 [00:13<01:14,  1.88it/s]\u001b[A\n",
      " 16%|        | 27/166 [00:14<01:14,  1.87it/s]\u001b[A\n",
      " 17%|        | 28/166 [00:14<01:12,  1.89it/s]\u001b[A\n",
      " 17%|        | 29/166 [00:15<01:11,  1.91it/s]\u001b[A\n",
      " 18%|        | 30/166 [00:15<01:12,  1.88it/s]\u001b[A\n",
      " 19%|        | 31/166 [00:16<01:11,  1.90it/s]\u001b[A\n",
      " 19%|        | 32/166 [00:16<01:10,  1.91it/s]\u001b[A\n",
      " 20%|        | 33/166 [00:17<01:11,  1.87it/s]\u001b[A\n",
      " 20%|        | 34/166 [00:17<01:10,  1.88it/s]\u001b[A\n",
      " 21%|        | 35/166 [00:18<01:09,  1.88it/s]\u001b[A\n",
      " 22%|       | 36/166 [00:18<01:09,  1.86it/s]\u001b[A\n",
      " 22%|       | 37/166 [00:19<01:08,  1.87it/s]\u001b[A\n",
      " 23%|       | 38/166 [00:20<01:07,  1.90it/s]\u001b[A\n",
      " 23%|       | 39/166 [00:20<01:07,  1.88it/s]\u001b[A\n",
      " 24%|       | 40/166 [00:21<01:06,  1.89it/s]\u001b[A\n",
      " 25%|       | 41/166 [00:21<01:05,  1.90it/s]\u001b[A\n",
      " 25%|       | 42/166 [00:22<01:05,  1.88it/s]\u001b[A\n",
      " 26%|       | 43/166 [00:22<01:05,  1.89it/s]\u001b[A\n",
      " 27%|       | 44/166 [00:23<01:03,  1.91it/s]\u001b[A\n",
      " 27%|       | 45/166 [00:23<01:03,  1.91it/s]\u001b[A\n",
      " 28%|       | 46/166 [00:24<01:02,  1.91it/s]\u001b[A\n",
      " 28%|       | 47/166 [00:24<01:02,  1.91it/s]\u001b[A\n",
      " 29%|       | 48/166 [00:25<01:03,  1.86it/s]\u001b[A\n",
      " 30%|       | 49/166 [00:25<01:02,  1.89it/s]\u001b[A\n",
      " 30%|       | 50/166 [00:26<01:02,  1.86it/s]\u001b[A\n",
      " 31%|       | 51/166 [00:26<01:03,  1.80it/s]\u001b[A\n",
      " 31%|      | 52/166 [00:27<01:02,  1.84it/s]\u001b[A\n",
      " 32%|      | 53/166 [00:28<01:00,  1.86it/s]\u001b[A\n",
      " 33%|      | 54/166 [00:28<01:00,  1.86it/s]\u001b[A\n",
      " 33%|      | 55/166 [00:29<00:59,  1.87it/s]\u001b[A\n",
      " 34%|      | 56/166 [00:29<00:58,  1.89it/s]\u001b[A\n",
      " 34%|      | 57/166 [00:30<00:58,  1.88it/s]\u001b[A\n",
      " 35%|      | 58/166 [00:30<00:56,  1.90it/s]\u001b[A\n",
      " 36%|      | 59/166 [00:31<00:56,  1.91it/s]\u001b[A\n",
      " 36%|      | 60/166 [00:31<00:56,  1.88it/s]\u001b[A\n",
      " 37%|      | 61/166 [00:32<00:55,  1.88it/s]\u001b[A\n",
      " 37%|      | 62/166 [00:32<00:54,  1.92it/s]\u001b[A\n",
      " 38%|      | 63/166 [00:33<00:54,  1.89it/s]\u001b[A\n",
      " 39%|      | 64/166 [00:33<00:53,  1.91it/s]\u001b[A\n",
      " 39%|      | 65/166 [00:34<00:53,  1.90it/s]\u001b[A\n",
      " 40%|      | 66/166 [00:34<00:53,  1.88it/s]\u001b[A\n",
      " 40%|      | 67/166 [00:35<00:52,  1.90it/s]\u001b[A\n",
      " 41%|      | 68/166 [00:35<00:51,  1.91it/s]\u001b[A\n",
      " 42%|     | 69/166 [00:36<00:51,  1.89it/s]\u001b[A\n",
      " 42%|     | 70/166 [00:36<00:50,  1.90it/s]\u001b[A\n",
      " 43%|     | 71/166 [00:37<00:50,  1.89it/s]\u001b[A\n",
      " 43%|     | 72/166 [00:38<00:50,  1.87it/s]\u001b[A\n",
      " 44%|     | 73/166 [00:38<00:49,  1.90it/s]\u001b[A\n",
      " 45%|     | 74/166 [00:39<00:48,  1.91it/s]\u001b[A\n",
      " 45%|     | 75/166 [00:39<00:48,  1.87it/s]\u001b[A\n",
      " 46%|     | 76/166 [00:40<00:47,  1.88it/s]\u001b[A\n",
      " 46%|     | 77/166 [00:40<00:46,  1.90it/s]\u001b[A\n",
      " 47%|     | 78/166 [00:41<00:47,  1.87it/s]\u001b[A\n",
      " 48%|     | 79/166 [00:41<00:46,  1.89it/s]\u001b[A\n",
      " 48%|     | 80/166 [00:42<00:45,  1.90it/s]\u001b[A\n",
      " 49%|     | 81/166 [00:42<00:45,  1.87it/s]\u001b[A\n",
      " 49%|     | 82/166 [00:43<00:44,  1.88it/s]\u001b[A\n",
      " 50%|     | 83/166 [00:43<00:43,  1.90it/s]\u001b[A\n",
      " 51%|     | 84/166 [00:44<00:44,  1.86it/s]\u001b[A\n",
      " 51%|     | 85/166 [00:44<00:43,  1.88it/s]\u001b[A\n",
      " 52%|    | 86/166 [00:45<00:42,  1.90it/s]\u001b[A\n",
      " 52%|    | 87/166 [00:45<00:41,  1.90it/s]\u001b[A\n",
      " 53%|    | 88/166 [00:46<00:41,  1.90it/s]\u001b[A\n",
      " 54%|    | 89/166 [00:47<00:40,  1.91it/s]\u001b[A\n",
      " 54%|    | 90/166 [00:47<00:40,  1.88it/s]\u001b[A\n",
      " 55%|    | 91/166 [00:48<00:39,  1.91it/s]\u001b[A\n",
      " 55%|    | 92/166 [00:48<00:38,  1.90it/s]\u001b[A\n",
      " 56%|    | 93/166 [00:49<00:39,  1.87it/s]\u001b[A\n",
      " 57%|    | 94/166 [00:49<00:37,  1.90it/s]\u001b[A\n",
      " 57%|    | 95/166 [00:50<00:37,  1.92it/s]\u001b[A\n",
      " 58%|    | 96/166 [00:50<00:36,  1.91it/s]\u001b[A\n",
      " 58%|    | 97/166 [00:51<00:36,  1.92it/s]\u001b[A\n",
      " 59%|    | 98/166 [00:51<00:35,  1.90it/s]\u001b[A\n",
      " 60%|    | 99/166 [00:52<00:35,  1.88it/s]\u001b[A\n",
      " 60%|    | 100/166 [00:52<00:34,  1.89it/s]\u001b[A\n",
      " 61%|    | 101/166 [00:53<00:34,  1.89it/s]\u001b[A\n",
      " 61%|   | 102/166 [00:53<00:33,  1.88it/s]\u001b[A\n",
      " 62%|   | 103/166 [00:54<00:33,  1.89it/s]\u001b[A\n",
      " 63%|   | 104/166 [00:54<00:32,  1.89it/s]\u001b[A\n",
      " 63%|   | 105/166 [00:55<00:32,  1.86it/s]\u001b[A\n",
      " 64%|   | 106/166 [00:56<00:31,  1.88it/s]\u001b[A\n",
      " 64%|   | 107/166 [00:56<00:31,  1.90it/s]\u001b[A\n",
      " 65%|   | 108/166 [00:57<00:30,  1.88it/s]\u001b[A\n",
      " 66%|   | 109/166 [00:57<00:31,  1.81it/s]\u001b[A\n",
      " 66%|   | 110/166 [00:58<00:31,  1.77it/s]\u001b[A\n",
      " 67%|   | 111/166 [00:58<00:32,  1.67it/s]\u001b[A\n",
      " 67%|   | 112/166 [00:59<00:38,  1.42it/s]\u001b[A\n",
      " 68%|   | 113/166 [01:00<00:37,  1.43it/s]\u001b[A\n",
      " 69%|   | 114/166 [01:01<00:39,  1.31it/s]\u001b[A\n",
      " 69%|   | 115/166 [01:02<00:40,  1.25it/s]\u001b[A\n",
      " 70%|   | 116/166 [01:02<00:35,  1.39it/s]\u001b[A\n",
      " 70%|   | 117/166 [01:03<00:32,  1.49it/s]\u001b[A\n",
      " 71%|   | 118/166 [01:04<00:31,  1.54it/s]\u001b[A\n",
      " 72%|  | 119/166 [01:04<00:32,  1.47it/s]\u001b[A\n",
      " 72%|  | 120/166 [01:05<00:30,  1.52it/s]\u001b[A\n",
      " 73%|  | 121/166 [01:06<00:29,  1.50it/s]\u001b[A\n",
      " 73%|  | 122/166 [01:06<00:28,  1.57it/s]\u001b[A\n",
      " 74%|  | 123/166 [01:07<00:27,  1.54it/s]\u001b[A\n",
      " 75%|  | 124/166 [01:08<00:31,  1.33it/s]\u001b[A\n",
      " 75%|  | 125/166 [01:09<00:30,  1.36it/s]\u001b[A\n",
      " 76%|  | 126/166 [01:09<00:31,  1.29it/s]\u001b[A\n",
      " 77%|  | 127/166 [01:10<00:28,  1.37it/s]\u001b[A\n",
      " 77%|  | 128/166 [01:11<00:25,  1.48it/s]\u001b[A\n",
      " 78%|  | 129/166 [01:11<00:23,  1.56it/s]\u001b[A\n",
      " 78%|  | 130/166 [01:12<00:22,  1.59it/s]\u001b[A\n",
      " 79%|  | 131/166 [01:12<00:22,  1.57it/s]\u001b[A\n",
      " 80%|  | 132/166 [01:13<00:21,  1.60it/s]\u001b[A\n",
      " 80%|  | 133/166 [01:14<00:19,  1.67it/s]\u001b[A\n",
      " 81%|  | 134/166 [01:14<00:18,  1.74it/s]\u001b[A\n",
      " 81%| | 135/166 [01:15<00:17,  1.72it/s]\u001b[A\n",
      " 82%| | 136/166 [01:15<00:17,  1.69it/s]\u001b[A\n",
      " 83%| | 137/166 [01:16<00:16,  1.72it/s]\u001b[A\n",
      " 83%| | 138/166 [01:16<00:15,  1.76it/s]\u001b[A\n",
      " 84%| | 139/166 [01:17<00:15,  1.79it/s]\u001b[A\n",
      " 84%| | 140/166 [01:17<00:14,  1.82it/s]\u001b[A\n",
      " 85%| | 141/166 [01:18<00:13,  1.80it/s]\u001b[A\n",
      " 86%| | 142/166 [01:19<00:13,  1.84it/s]\u001b[A\n",
      " 86%| | 143/166 [01:19<00:12,  1.85it/s]\u001b[A\n",
      " 87%| | 144/166 [01:20<00:11,  1.84it/s]\u001b[A\n",
      " 87%| | 145/166 [01:20<00:11,  1.87it/s]\u001b[A\n",
      " 88%| | 146/166 [01:21<00:10,  1.87it/s]\u001b[A\n",
      " 89%| | 147/166 [01:21<00:10,  1.84it/s]\u001b[A\n",
      " 89%| | 148/166 [01:22<00:09,  1.86it/s]\u001b[A\n",
      " 90%| | 149/166 [01:22<00:09,  1.84it/s]\u001b[A\n",
      " 90%| | 150/166 [01:23<00:09,  1.60it/s]\u001b[A\n",
      " 91%| | 151/166 [01:24<00:09,  1.63it/s]\u001b[A\n",
      " 92%|| 152/166 [01:24<00:08,  1.66it/s]\u001b[A\n",
      " 92%|| 153/166 [01:25<00:07,  1.68it/s]\u001b[A\n",
      " 93%|| 154/166 [01:25<00:07,  1.67it/s]\u001b[A\n",
      " 93%|| 155/166 [01:26<00:06,  1.67it/s]\u001b[A\n",
      " 94%|| 156/166 [01:27<00:05,  1.71it/s]\u001b[A\n",
      " 95%|| 157/166 [01:27<00:05,  1.76it/s]\u001b[A\n",
      " 95%|| 158/166 [01:28<00:04,  1.81it/s]\u001b[A\n",
      " 96%|| 159/166 [01:28<00:03,  1.81it/s]\u001b[A\n",
      " 96%|| 160/166 [01:29<00:03,  1.85it/s]\u001b[A\n",
      " 97%|| 161/166 [01:29<00:02,  1.87it/s]\u001b[A\n",
      " 98%|| 162/166 [01:30<00:02,  1.84it/s]\u001b[A\n",
      " 98%|| 163/166 [01:30<00:01,  1.85it/s]\u001b[A\n",
      " 99%|| 164/166 [01:31<00:01,  1.87it/s]\u001b[A\n",
      " 99%|| 165/166 [01:31<00:00,  1.88it/s]\u001b[A\n",
      "100%|| 166/166 [01:32<00:00,  1.80it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  5.046345651508814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|         | 1/21 [00:00<00:05,  3.69it/s]\u001b[A\n",
      " 10%|         | 2/21 [00:00<00:04,  3.86it/s]\u001b[A\n",
      " 14%|        | 3/21 [00:00<00:04,  3.99it/s]\u001b[A\n",
      " 19%|        | 4/21 [00:00<00:04,  3.99it/s]\u001b[A\n",
      " 24%|       | 5/21 [00:01<00:03,  4.08it/s]\u001b[A\n",
      " 29%|       | 6/21 [00:01<00:03,  4.14it/s]\u001b[A\n",
      " 33%|      | 7/21 [00:01<00:03,  4.25it/s]\u001b[A\n",
      " 38%|      | 8/21 [00:01<00:03,  4.21it/s]\u001b[A\n",
      " 43%|     | 9/21 [00:02<00:02,  4.18it/s]\u001b[A\n",
      " 48%|     | 10/21 [00:02<00:02,  4.14it/s]\u001b[A\n",
      " 52%|    | 11/21 [00:02<00:02,  4.14it/s]\u001b[A\n",
      " 57%|    | 12/21 [00:02<00:02,  4.19it/s]\u001b[A\n",
      " 62%|   | 13/21 [00:03<00:01,  4.18it/s]\u001b[A\n",
      " 67%|   | 14/21 [00:03<00:01,  4.18it/s]\u001b[A\n",
      " 71%|  | 15/21 [00:03<00:01,  4.14it/s]\u001b[A\n",
      " 76%|  | 16/21 [00:03<00:01,  4.11it/s]\u001b[A\n",
      " 81%|  | 17/21 [00:04<00:00,  4.15it/s]\u001b[A\n",
      " 86%| | 18/21 [00:04<00:00,  4.16it/s]\u001b[A\n",
      " 90%| | 19/21 [00:04<00:00,  4.12it/s]\u001b[A\n",
      " 95%|| 20/21 [00:04<00:00,  4.17it/s]\u001b[A\n",
      "100%|| 21/21 [00:04<00:00,  4.22it/s]\u001b[A\n",
      "100%|| 2/2 [03:25<00:00, 102.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9940259437424637 best epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok = True)\n",
    "best_score = 0.0\n",
    "best_epoch = 0\n",
    "for epoch in trange(epochs):\n",
    "    train(model, train_data, loss_func, optimizer)\n",
    "    val_score = evaluate(model, val_data, metric_func)\n",
    "    \n",
    "    if val_score > best_score:\n",
    "        best_score = val_score\n",
    "        best_epoch = epoch\n",
    "#         save_checkpoint(model, os.path.join(save_dir, \"model.pt\"))\n",
    "\n",
    "print(\"best score: \", str(best_score), \"best epoch:\", str(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:05<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score:  0.9934215069588677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_score = evaluate(model, test_data, metric_func)\n",
    "print(\"test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create metadata file for evaluation graphs\n",
    "metadata_eval_folder_name = \"metadata_eval\"\n",
    "metadata_eval_file_name = \"metadata_eval.json\"\n",
    "data = []\n",
    "for root, subfolders, files in os.walk(evaluation_dataset_name):\n",
    "    for f in files:\n",
    "        if f[:5] == \"empty\":\n",
    "            graph_path = os.path.join(root, f)\n",
    "            target_path = os.path.join(root, \"target.\"+f[-4:])\n",
    "            uid = f[f.find('.') + 1:f.find('.') + 5]\n",
    "            data.append({'graph_path': graph_path, 'target_path': target_path, 'uid': uid})\n",
    "os.makedirs(metadata_eval_folder_name, exist_ok=True)\n",
    "json.dump(data, open(metadata_eval_folder_name+'/'+metadata_eval_file_name, 'w'), indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata_eval = json.load(open(metadata_eval_folder_name+'/'+metadata_eval_file_name, 'r'))\n",
    "eval_data = GraphDataset(metadata_eval)\n",
    "eval_data = DataLoader(eval_data, 1)\n",
    "eval_iter = iter(eval_data)\n",
    "\n",
    "one_hot_features = np.zeros((num_nodes, num_nodes))  # Create a one-hot mapping for remaining node degree\n",
    "np.fill_diagonal(one_hot_features, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = next(eval_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_eval = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [5., 5., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 4., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 3., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 4., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 3., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 4., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 3., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(graph_eval)\n",
    "#         out = torch.nn.Softmax(dim=0)(out1)\n",
    "        \n",
    "\n",
    "#     xk = np.arange(graph_eval.edge_attr.size(0))\n",
    "#     pk = np.array(out).squeeze()\n",
    "#     prob = stats.rv_discrete(name='prob', values=(xk, pk))\n",
    "#     edge_choice = prob.rvs()\n",
    "\n",
    "    edge_choice = torch.argmax(out).item()\n",
    "\n",
    "    graph_eval.edge_attr[edge_choice] = 1.0\n",
    "    graph_eval.x[graph_eval.edge_index[0][edge_choice].item()][1] += 1.0\n",
    "    graph_eval.x[graph_eval.edge_index[0][edge_choice].item()][2] -= 1.0\n",
    "    graph_eval.x[graph_eval.edge_index[1][edge_choice].item()][1] += 1.0\n",
    "    graph_eval.x[graph_eval.edge_index[1][edge_choice].item()][2] -= 1.0\n",
    "    graph_eval.x[graph_eval.edge_index[0][edge_choice].item()][3:] = torch.tensor(one_hot_features[int(graph_eval.x[graph_eval.edge_index[0][edge_choice].item()][2].item())])\n",
    "    graph_eval.x[graph_eval.edge_index[1][edge_choice].item()][3:] = torch.tensor(one_hot_features[int(graph_eval.x[graph_eval.edge_index[1][edge_choice].item()][2].item())])\n",
    "\n",
    "graph_eval.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9882e-01],\n",
       "        [9.9882e-01],\n",
       "        [9.9895e-01],\n",
       "        [3.9817e-04]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2969],\n",
       "        [0.2969],\n",
       "        [0.2969],\n",
       "        [0.1094]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=0)(out1[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol-inverse",
   "language": "python",
   "name": "mol-inverse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
